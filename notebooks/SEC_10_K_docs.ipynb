{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Introduction**\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://getindexify.ai/\"><img src=\"https://getindexify.ai/images/logos/base2.svg\" width=\"145\"></a>\n",
        "  <a href=\"https://discord.com/invite/kF8UZACA7r\"><img src=\"https://raw.githubusercontent.com/rishiraj/random/main/Discord%20button.png\" width=\"145\"></a><br>\n",
        "  Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/tensorlakeai/indexify\">Github</a></i> ⭐\n",
        "</div>\n",
        "\n",
        "This notebook demonstrates how Indexify can make it easier to quickly extract insights from complex SEC filings like the Form 10-K annual report. Using Uber's 10-K as an example, we show how the Indexify library can enable question answering on the filing text to get rapid answers. We also illustrate how schema-based extraction can pull key data points from the unstructured document. The combination of question answering and schema-based extraction provides a powerful toolkit to derive insights from dense financial filings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9NVuXFG3qGw"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install indexify indexify-extractor-sdk\n",
        "\n",
        "# # Download Indexify Server\n",
        "# !curl https://getindexify.ai | sh\n",
        "\n",
        "# # Install Poppler (required for PDF extraction)\n",
        "# # You can use brew on MacOS.\n",
        "# !sudo apt-get install -y poppler-utils\n",
        "\n",
        "# # Download Extractors\n",
        "# !indexify-extractor download tensorlake/chunk-extractor\n",
        "# !indexify-extractor download tensorlake/minilm-l6\n",
        "# !indexify-extractor download tensorlake/pdfextractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEHbUyCM3-vm"
      },
      "source": [
        "After installing the necessary libraries, download the server, and the extractors, you need to restart the runtime. Then, you have to run Indexify Server with the Extractors.\n",
        "\n",
        "Open 2 terminals and run the following commands:\n",
        "\n",
        "```bash\n",
        "# Terminal 1\n",
        "./indexify server -d\n",
        "\n",
        "# Terminal 2\n",
        "indexify-extractor join-server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Test the extractors**\n",
        "\n",
        "We will try PDFExtractor first. The PDFExtractor can extract all the values from text as well as tables in one shot and passes it to the next chained extractors which can be used for question answering.\n",
        "\n",
        "We'll start by downloading Uber's Form 10-K report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "req = requests.get(\"https://d18rn0p25nwr6d.cloudfront.net/CIK-0001543151/6fabd79a-baa9-4b08-84fe-deab4ef8415f.pdf\")\n",
        "\n",
        "with open('form10-k.pdf','wb') as f:\n",
        "    f.write(req.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/quamer23nasim38/venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Invalid directory: /home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify/indexify-extractor-template-main/custom_extractor:MyExtractor",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_indexify_extractors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcustom_extractor:MyExtractor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/indexify_extractor_sdk/module_loader.py:13\u001b[0m, in \u001b[0;36mload_indexify_extractors\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m Path(base_path)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_dir\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Add the base path's parent to sys.path for dynamic imports\u001b[39;00m\n\u001b[1;32m     16\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(base_dir\u001b[38;5;241m.\u001b[39mparent))\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid directory: /home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify/indexify-extractor-template-main/custom_extractor:MyExtractor"
          ]
        }
      ],
      "source": [
        "load_indexify_extractors(\"custom_extractor:MyExtractor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_indexify_extractors(\"/home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify/indexify-extractor-template-main/custom_extractor.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Invalid directory: /home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify/notebooks/indexify_extractors.pdfextractor.pdf_extractor:PDFExtractor",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mindexify_extractor_sdk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_indexify_extractors, Content\n\u001b[0;32m----> 3\u001b[0m pdfextractor, pdfconfig_cls \u001b[38;5;241m=\u001b[39m \u001b[43mload_indexify_extractors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindexify_extractors.pdfextractor.pdf_extractor:PDFExtractor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m content \u001b[38;5;241m=\u001b[39m Content\u001b[38;5;241m.\u001b[39mfrom_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mform10-k.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m pdfconfig_cls()\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/indexify_extractor_sdk/module_loader.py:13\u001b[0m, in \u001b[0;36mload_indexify_extractors\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m Path(base_path)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_dir\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Add the base path's parent to sys.path for dynamic imports\u001b[39;00m\n\u001b[1;32m     16\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(base_dir\u001b[38;5;241m.\u001b[39mparent))\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid directory: /home/quamer23nasim38/faster-patient-onboarding-from-medical-history-using-indexify/notebooks/indexify_extractors.pdfextractor.pdf_extractor:PDFExtractor"
          ]
        }
      ],
      "source": [
        "from indexify_extractor_sdk import load_indexify_extractors, Content\n",
        "\n",
        "pdfextractor, pdfconfig_cls = load_indexify_extractors(\"indexify_extractors.pdfextractor.pdf_extractor:PDFExtractor\")\n",
        "content = Content.from_file(\"form10-k.pdf\")\n",
        "config = pdfconfig_cls()\n",
        "\n",
        "pdf_result = pdfextractor.extract(content, config)\n",
        "text_content = next(content.data.decode('utf-8') for content in pdf_result if content.content_type == 'text/plain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(text_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIlKuPp6wxg"
      },
      "source": [
        "## **Create a Client**\n",
        "Instantiate the Indexify Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HZNysNl-631k"
      },
      "outputs": [],
      "source": [
        "from indexify import IndexifyClient\n",
        "client = IndexifyClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Question Answering Task**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQr1749x6_CW"
      },
      "source": [
        "### **Extraction Graph Setup**\n",
        "\n",
        "1. Import the `ExtractionGraph` class from the `indexify` package.\n",
        "\n",
        "2. Define the extraction graph specification in YAML format:\n",
        "   - Set the name of the extraction graph to \"pdfqa\".\n",
        "   - Define the extraction policies:\n",
        "     - Use the \"tensorlake/pdfextractor\" extractor for PDF marking and name it \"docextractor\".\n",
        "     - Use the \"tensorlake/chunk-extractor\" for text chunking and name it \"chunks\".\n",
        "       - Set the input parameters for the chunker:\n",
        "         - `chunk_size`: 1000 (size of each text chunk)\n",
        "         - `overlap`: 100 (overlap between chunks)\n",
        "         - `content_source`: \"docextractor\" (source of content for chunking)\n",
        "     - Use the \"tensorlake/minilm-l6\" extractor for embedding and name it \"get-embeddings\".\n",
        "       - Set the content source for embedding to \"chunks\".\n",
        "\n",
        "3. Create an `ExtractionGraph` object from the YAML specification using `ExtractionGraph.from_yaml()`.\n",
        "\n",
        "4. Create the extraction graph on the Indexify client using `client.create_extraction_graph()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from indexify import ExtractionGraph\n",
        "\n",
        "extraction_graph_spec = \"\"\"\n",
        "name: 'pdfqa2'\n",
        "extraction_policies:\n",
        "   - extractor: 'tensorlake/pdfextractor'\n",
        "     name: 'docextractor'\n",
        "   - extractor: 'tensorlake/chunk-extractor'\n",
        "     name: 'chunker'\n",
        "     input_params:\n",
        "        chunk_size: 1000\n",
        "        overlap: 100\n",
        "     content_source: 'docextractor'\n",
        "   - extractor: 'tensorlake/minilm-l6'\n",
        "     name: 'embedder'\n",
        "     content_source: 'chunker'\n",
        "\"\"\"\n",
        "\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGqpkx3P7gsh"
      },
      "source": [
        "### **Upload the FORM 10-K PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ETideBqK8GGp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for extraction to complete for content id:  a3cdb41598978a01\n",
            "Extraction completed for content id:  a3cdb41598978a01\n"
          ]
        }
      ],
      "source": [
        "content_id = client.upload_file(\"pdfqa2\", \"form10-k_.pdf\")\n",
        "client.wait_for_extraction(content_id)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WDexIU8LFy"
      },
      "source": [
        "### **What is happening behind the scenes**\n",
        "\n",
        "Indexify is designed to seamlessly respond to ingestion events by assessing all existing policies and triggering the necessary extractors for extraction. Once the PDF extractor completes the process of extracting texts, bytes, and JSONs from the document, it automatically initiates the embedding extractor to chunk the content, extract embeddings, and populate an index.\n",
        "\n",
        "With Indexify, you have the ability to upload hundreds of PDF files simultaneously, and the platform will efficiently handle the extraction and indexing of the contents without requiring manual intervention. To expedite the extraction process, you can deploy multiple instances of the extractors, and Indexify's built-in scheduler will transparently distribute the workload among them, ensuring optimal performance and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6SQ0xDt9a_9"
      },
      "source": [
        "### **Perform RAG with OpenAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2raD6aeB9Th1"
      },
      "outputs": [],
      "source": [
        "def get_context(question: str, index: str, top_k=3):\n",
        "    results = client.search_index(name=index, query=question, top_k=top_k)\n",
        "    context = \"\"\n",
        "    for result in results:\n",
        "        context = context + f\"content id: {result['content_id']} \\n\\n passage: {result['text']}\\n\"\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ApiException",
          "evalue": "status: Aborted, message: \"Index with id 352c626f03d56331 not found\", details: [], metadata: MetadataMap { headers: {\"content-type\": \"application/grpc\", \"date\": \"Thu, 22 Aug 2024 07:55:48 GMT\", \"content-length\": \"0\"} }",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the disclosure with respect to Foreign Subsidiaries?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpdfqa.embedder.embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m context\n",
            "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m(question, index, top_k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m, index: \u001b[38;5;28mstr\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/indexify/client.py:539\u001b[0m, in \u001b[0;36mIndexifyClient.search_index\u001b[0;34m(self, name, query, top_k, filters)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03mSearch index in the current namespace.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m    - filters (List[str]): list of filters to apply\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    538\u001b[0m req \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m\"\u001b[39m: filters}\n\u001b[0;32m--> 539\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnamespaces/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/indexes/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/indexify/client.py:207\u001b[0m, in \u001b[0;36mIndexifyClient.post\u001b[0;34m(self, endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, endpoint: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    Make a POST request to the Indexify service.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.9/site-packages/indexify/client.py:161\u001b[0m, in \u001b[0;36mIndexifyClient._request\u001b[0;34m(self, method, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ApiException(\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus code: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m status_code \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m request args: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(kwargs)\n\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status_code\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ApiException(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;66;03m# error = Error.from_tonic_error_string(str(response.url), response.text)\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;66;03m# self.__print_additional_error_context(error)\u001b[39;00m\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# raise error\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n",
            "\u001b[0;31mApiException\u001b[0m: status: Aborted, message: \"Index with id 352c626f03d56331 not found\", details: [], metadata: MetadataMap { headers: {\"content-type\": \"application/grpc\", \"date\": \"Thu, 22 Aug 2024 07:55:48 GMT\", \"content-length\": \"0\"} }"
          ]
        }
      ],
      "source": [
        "question = \"What are the disclosure with respect to Foreign Subsidiaries?\"\n",
        "context = get_context(question, \"pdfqa.embedder.embedding\")\n",
        "context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_prompt(question, context):\n",
        "    return f\"Answer the question, based on the context.\\n question: {question} \\n context: {context}\"\n",
        "\n",
        "prompt = create_prompt(question, context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client_openai = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckexWnEe-B3c"
      },
      "source": [
        "Now ask any question related to the ingested FORM 10-K PDF document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSc4uBLA-IEB"
      },
      "outputs": [],
      "source": [
        "chat_completion = client_openai.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Schema-based Retrieval Task**\n",
        "Alert: The following example will cost a lot of OpenAI credits. Move ahead at your own risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Extraction Graph Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "extraction_graph_spec = \"\"\"\n",
        "name: 'pdfschema3'\n",
        "extraction_policies:\n",
        "   - extractor: 'tensorlake/pdfextractor'\n",
        "     name: 'docextractor'\n",
        "   - extractor: 'tensorlake/schema'\n",
        "     name: 'schemaprocessor'\n",
        "     input_params:\n",
        "        service: 'openai'\n",
        "        schema: {'properties': {'file_number': {'title': 'File Number', 'type': 'string'}, 'registrant_name': {'title': 'Registrant Name', 'type': 'string'}, 'jurisdiction': {'title': 'Jurisdiction', 'type': 'string'}, 'employer_id_number': {'title': 'Employer Id Number', 'type': 'string'}, 'address': {'title': 'Address', 'type': 'string'}, 'telephone_number': {'title': 'Telephone Number', 'type': 'string'}, 'title_of_each_class': {'title': 'Title Of Each Class', 'type': 'string'}, 'trading_symbol': {'title': 'Trading Symbol', 'type': 'string'}, 'name_of_exchange': {'title': 'Name Of Exchange', 'type': 'string'}}, 'required': ['file_number', 'registrant_name', 'jurisdiction', 'employer_id_number', 'address', 'telephone_number', 'title_of_each_class', 'trading_symbol', 'name_of_exchange'], 'title': 'Form', 'type': 'object'}\n",
        "     content_source: 'docextractor'\n",
        "\"\"\"\n",
        "\n",
        "extraction_graph = ExtractionGraph.from_yaml(extraction_graph_spec)\n",
        "client.create_extraction_graph(extraction_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Upload the FORM 10-K PDF File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for extraction to complete for content id:  bb896dc28537dea2\n",
            "Extraction completed for content id:  bb896dc28537dea2\n"
          ]
        }
      ],
      "source": [
        "content_id = client.upload_file(\"pdfschema3\", \"form10-k_.pdf\")\n",
        "client.wait_for_extraction(content_id)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **View the extracted content**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': '571abd40144c1f67',\n",
              "  'mime_type': 'text/plain',\n",
              "  'content': b'{\"name\":\"Uber Technologies, Inc.\"}'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_extracted_content(content_id, 'pdfschema3', 'schemaprocessor')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
